# =============================================================================
# CON-LLM-CONTAINER ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and customize the values for your environment
# This configuration supports all Phase 0 services: LocalAI, Qdrant, PostgreSQL, Redis, FastAPI-Gateway, and MinIO

# =============================================================================
# CORE SERVICES CONFIGURATION
# =============================================================================

# FastAPI Gateway Configuration
# ----------------------------
# Internal API port (inside container)
API_PORT=8000

# External port mappings for different services
MAIN_API_PORT=8080          # Main FastAPI gateway service
LOCALAI_PORT=8081           # LocalAI service port
QDRANT_PORT=6333            # Qdrant vector database port
POSTGRES_PORT=5432          # PostgreSQL database port
REDIS_PORT=6379             # Redis cache port
MINIO_API_PORT=9000         # MinIO S3-compatible storage API port
MINIO_CONSOLE_PORT=9001     # MinIO web console port

# LocalAI Configuration
# ---------------------
# Host and port for LocalAI service (internal container communication)
LOCALAI_HOST=localai
LOCALAI_PORT=8080

# Default model to use (must be available in LocalAI)
# Popular options: llama-3.2-1b-instruct, llama-3.2-3b-instruct, codellama-7b-instruct
DEFAULT_MODEL=llama-3.2-1b-instruct

# GPU Configuration
# -----------------
# Enable debug mode for LocalAI (useful for GPU troubleshooting)
DEBUG=false

# Backend Performance & Logging
# -----------------------------
# API request timeout in seconds
API_TIMEOUT=300

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# PostgreSQL Configuration
# ------------------------
POSTGRES_DB=con_selfrag
POSTGRES_USER=con_selfrag
POSTGRES_PASSWORD=con_selfrag_secure_password_2024

# Redis Configuration
# -------------------
REDIS_HOST=redis
REDIS_PORT=6379

# Qdrant Configuration
# --------------------
QDRANT_HOST=qdrant
QDRANT_PORT=6333

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================

# Docker Volume Paths
# -------------------
# Model storage location (large files - LLM models)
LOCALAI_MODELS_PATH=./models

# Application data location
DATA_PATH=./data

# Application logs location
LOGS_PATH=./logs

# MinIO Configuration (Optional Document Storage)
# ----------------------------------------------
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123

# =============================================================================
# DOCKER COMPOSE PROFILES
# =============================================================================
# Available profiles:
# - default: All services (FastAPI, LocalAI, Qdrant, PostgreSQL, Redis)
# - storage: Includes MinIO for document storage
# - dev: Development services with hot reload

# =============================================================================
# DEVELOPMENT & DEBUGGING
# =============================================================================

# Development Mode Settings
# -------------------------
# Set to true to enable development features
DEBUG_MODE=false

# Enable hot reload for backend (development only)
BACKEND_RELOAD=false

# Enable verbose logging for troubleshooting
VERBOSE_LOGGING=false

# =============================================================================
# BACKUP & RESTORE CONFIGURATION
# =============================================================================

# Backup Settings
# ---------------
BACKUP_PATH=./backups
BACKUP_RETENTION_DAYS=30
BACKUP_SCHEDULE=0 2 * * *  # Daily at 2 AM

# =============================================================================
# SECURITY CONSIDERATIONS
# =============================================================================
# 
# IMPORTANT: This file contains configuration for your LLM container setup.
# 
# 1. Never commit .env files to version control
# 2. Use strong, unique values for any authentication tokens
# 3. Restrict network access to only necessary ports
# 4. Regularly update your models and dependencies
# 5. Monitor resource usage, especially for model storage
#
# For production deployments:
# - Use Docker secrets or external secret management
# - Enable HTTPS/TLS termination
# - Implement proper access controls
# - Set up monitoring and logging
# =============================================================================

# =============================================================================
# SELF-RAG LLM API CONFIGURATION
# =============================================================================
# Copy this file to .env and adjust values as needed

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# =============================================================================
# LOCALAI CONFIGURATION
# =============================================================================
# LocalAI service connection settings
LOCALAI_HOST=localhost
LOCALAI_PORT=8080
LOCALAI_TIMEOUT=30.0

# Default model for LLM operations
# Common options: llama-3.2-1b-instruct, phi-3-mini, ggml-stablelm
DEFAULT_MODEL=llama-3.2-1b-instruct

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# PostgreSQL settings
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=con_selfrag
POSTGRES_PASSWORD=con_selfrag_password
POSTGRES_DB=con_selfrag

# Redis settings
REDIS_HOST=localhost
REDIS_PORT=6379

# Qdrant vector database settings
QDRANT_HOST=localhost
QDRANT_PORT=6333

# =============================================================================
# AUTHENTICATION & SECURITY CONFIGURATION
# =============================================================================

# JWT Configuration
# -----------------
# CRITICAL: Change this secret key in production! Use a strong, random key.
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production-please-use-random-key

# JWT token expiration time in minutes (default: 24 hours)
JWT_EXPIRE_MINUTES=1440

# JWT signing algorithm (HS256 recommended for most use cases)
JWT_ALGORITHM=HS256

# Password Security
# -----------------
# Minimum password length for user registration
PASSWORD_MIN_LENGTH=8

# API Key Settings
# ----------------
# Default API key expiration in days
API_KEY_EXPIRE_DAYS=365

# Rate Limiting & Security
# ------------------------
# Maximum login attempts before account lockout
MAX_LOGIN_ATTEMPTS=5

# Account lockout duration in minutes
LOCKOUT_DURATION_MINUTES=15

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================
# CORS settings (comma-separated list)
CORS_ORIGINS=*

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# =============================================================================
# DOCKER COMPOSE OVERRIDES
# =============================================================================
# When running with Docker Compose, these values are automatically set:
# LOCALAI_HOST=localai
# POSTGRES_HOST=postgres
# REDIS_HOST=redis
# QDRANT_HOST=qdrant

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# For local development without Docker:
# LOCALAI_HOST=localhost
# POSTGRES_HOST=localhost
# REDIS_HOST=localhost
# QDRANT_HOST=localhost
