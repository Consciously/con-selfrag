{
  "milestone": "Milestone 3 - LLM Container Integration",
  "total_tests": 8,
  "passed_tests": 3,
  "failed_tests": 5,
  "success_rate": 37.5,
  "duration_seconds": 90.19,
  "test_results": {
    "Health Endpoints": {
      "main_health": {
        "status_code": 200,
        "success": true,
        "has_localai": true,
        "response": {
          "status": "healthy",
          "overall_status": "healthy",
          "services": {
            "postgres": "healthy",
            "redis": "healthy",
            "qdrant": "healthy",
            "localai": "healthy"
          },
          "timestamp": "2025-08-01T13:43:16.661656Z"
        }
      },
      "services_detailed": {
        "status_code": 200,
        "success": true,
        "has_localai": true,
        "localai_status": "healthy",
        "response": {
          "overall_status": "healthy",
          "services": {
            "postgres": {
              "status": "healthy",
              "schema_exists": true,
              "tables_found": [
                "conversations",
                "document_chunks",
                "documents",
                "messages"
              ],
              "message": "PostgreSQL connection successful"
            },
            "redis": {
              "status": "healthy",
              "version": "7.4.5",
              "message": "Redis connection successful"
            },
            "qdrant": {
              "status": "healthy",
              "collections_count": 0,
              "cluster_info": {
                "result": {
                  "status": "disabled"
                },
                "status": "ok",
                "time": 1.042e-06
              },
              "message": "Qdrant connection successful"
            },
            "localai": {
              "status": "healthy",
              "models_count": 9,
              "available_models": [
                "stablediffusion",
                "gpt-4o",
                "tts-1",
                "silero-vad",
                "jina-reranker-v1-base-en",
                "gpt-4",
                "text-embedding-ada-002",
                "whisper-1",
                "minicpm-v-2_6-mmproj-f16.gguf"
              ],
              "message": "LocalAI connection successful"
            }
          },
          "timestamp": "2025-08-01T13:43:16.686309Z"
        }
      },
      "readiness": {
        "status_code": 200,
        "success": true,
        "has_localai": true,
        "response": {
          "status": "ready",
          "services": {
            "postgres": {
              "status": "healthy",
              "schema_exists": true,
              "tables_found": [
                "conversations",
                "document_chunks",
                "documents",
                "messages"
              ],
              "message": "PostgreSQL connection successful"
            },
            "redis": {
              "status": "healthy",
              "version": "7.4.5",
              "message": "Redis connection successful"
            },
            "qdrant": {
              "status": "healthy",
              "collections_count": 0,
              "cluster_info": {
                "result": {
                  "status": "disabled"
                },
                "status": "ok",
                "time": 5.61e-07
              },
              "message": "Qdrant connection successful"
            },
            "localai": {
              "status": "healthy",
              "models_count": 9,
              "available_models": [
                "whisper-1",
                "stablediffusion",
                "gpt-4o",
                "tts-1",
                "silero-vad",
                "jina-reranker-v1-base-en",
                "gpt-4",
                "text-embedding-ada-002",
                "minicpm-v-2_6-mmproj-f16.gguf"
              ],
              "message": "LocalAI connection successful"
            }
          },
          "timestamp": "2025-08-01T13:43:16.711347Z"
        }
      }
    },
    "LLM Health": {
      "status_code": 200,
      "success": true,
      "response": {
        "status": "healthy",
        "service": "LocalAI",
        "timestamp": "2025-08-01T13:43:16Z",
        "message": "LLM service is operational"
      }
    },
    "List Models": {
      "status_code": 200,
      "success": true,
      "response": [
        {
          "name": "whisper-1",
          "size": null,
          "digest": null,
          "details": null
        },
        {
          "name": "stablediffusion",
          "size": null,
          "digest": null,
          "details": null
        },
        {
          "name": "gpt-4o",
          "size": null,
          "digest": null,
          "details": null
        },
        {
          "name": "tts-1",
          "size": null,
          "digest": null,
          "details": null
        },
        {
          "name": "silero-vad",
          "size": null,
          "digest": null,
          "details": null
        },
        {
          "name": "jina-reranker-v1-base-en",
          "size": null,
          "digest": null,
          "details": null
        },
        {
          "name": "gpt-4",
          "size": null,
          "digest": null,
          "details": null
        },
        {
          "name": "text-embedding-ada-002",
          "size": null,
          "digest": null,
          "details": null
        },
        {
          "name": "minicpm-v-2_6-mmproj-f16.gguf",
          "size": null,
          "digest": null,
          "details": null
        }
      ]
    },
    "Text Generation": {
      "error": "",
      "success": false
    },
    "Streaming Generation": {
      "error": "",
      "success": false
    },
    "Question Answering": {
      "error": "",
      "success": false
    },
    "Validation & Errors": {
      "empty_prompt": {
        "status_code": 400,
        "success": true,
        "response": {
          "detail": "Prompt cannot be empty"
        }
      },
      "empty_question": {
        "status_code": 400,
        "success": true,
        "response": {
          "detail": "Question cannot be empty"
        }
      },
      "streaming_flag_error": {
        "status_code": 400,
        "success": true,
        "response": {
          "detail": "Streaming not supported in this endpoint. Use /generate/stream for streaming responses."
        }
      }
    },
    "OpenAPI Documentation": {
      "docs_available": true,
      "openapi_status_code": 200,
      "llm_endpoints_count": 5,
      "llm_endpoints": [
        "/llm/generate",
        "/llm/generate/stream",
        "/llm/ask",
        "/llm/models",
        "/llm/health"
      ],
      "success": true
    }
  },
  "overall_success": false
}